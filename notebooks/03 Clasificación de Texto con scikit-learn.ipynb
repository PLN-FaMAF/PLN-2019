{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Texto con scikit-learn\n",
    "\n",
    "Basado en: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "Este tutorial es sobre clasificación de texto pero bien puede servir como una rápida introducción general a scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus\n",
    "\n",
    "Primero cargamos un corpus de categorización de texto. En nuestro caso, usamos un subconjunto del corpus \"20 newsgroups\", que se compone de 2257 posts en foros de cuatro temáticas diferentes (ateísmo, cristianismo, gráficos de computadora y medicina):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 2257)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "len(twenty_train.data), len(twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos por ejemplo el primer documento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que este documento corresponde al tema de gráficos de computadora ('comp.graphics'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.graphics'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[0]\n",
    "twenty_train.target_names[twenty_train.target[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features: Bag of Words\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Los features van a ser las palabras de los posts (*bag-of-words*). Más precisamente, vamos a contar la frecuencia de aparición de cada palabra en cada documento. Para eso podemos usar la clase `CountVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_counts tiene una fila por cada documento (post) y una columna por cada feature. Podemos consultar a qué índice corresponde cada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = count_vect.get_feature_names()\n",
    "features.index('converting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá vemos que la palabra 'converting' tiene índice 9805. Podemos confirmar que el conteo de la palabra 'converting' para el primer documento es 2 (se cuenta dos veces porque CountVectorizer ignora mayúsculas por defecto):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0,9805]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices Dispersas (o Ralas)\n",
    "\n",
    "De las ~36000 palabras que observamos en la totalidad de los documentos, sólo muy pocas van a aparecer en cada documento individualmente. Esto quiere decir que la gran mayoría de las entradas de la matriz de conteo van a ser ceros. Este tipo de matrices se llaman matrices esparsas, dispersas o ralas (*sparse matrices* en inglés).\n",
    "\n",
    "Por suerte, existen implementaciones de matrices dispersas que no guardan explícitamente todas las entradas de la matriz si no sólo las que son distintas de cero.\n",
    "\n",
    "Scipy trae varias versiones de matrices esparsas, y el `CountVectorizer` devuelve este tipo de matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2257x35788 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 365886 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la matriz es 2257x35788 y tiene 365886 elementos distintos de cero. Haciendo la cuenta vemos que sólo un 0.4% de las entradas de la matriz son distintas de cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004529776814469733"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365886.0 / (2257*35788)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features: Preprocesamiento\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "- https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "\n",
    "Los features así como están tienen dos problemas:\n",
    "\n",
    "1. Los documentos más largos van a tener más counts para todos los features.\n",
    "2. Las palabras más frecuentes (las funcionales, como los artículos y las preposiciones) son poco informativas ya que aparecen mucho en todos los temas.\n",
    "\n",
    "Estos dos problemas meten ruido en los features que hace más difícil que sobresalgan los features realmente informativos. La solución es hacer un *downscaling* de ambas cosas, llamado [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf). Scikit-learn provee el `TfidfTransformer` para hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver, por ejemplo, que el conteo para la palabra 'converting' en el primer documento ahora está normalizado (antes valía 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21567205914741702"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf[0,9805]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador Multinomial Naive-Bayes\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes\n",
    "\n",
    "Ahora que ya tenemos los features con el debido preprocesamiento, podemos instanciar y entrenar un clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pueden ver, para el entrenamiento pasamos como parámetro una matriz con los vectores de features para cada documento (uno por fila) y la lista de etiquetas de los documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el clasificador, se puede utilizar para predecir la clasificación de nuevos documentos. Por supuesto, antes se debe pasar los documentos por el mismo preprocesamiento que se usó al entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('soc.religion.christian', 'comp.graphics')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[3], twenty_train.target_names[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente 'God is love' se clasifica como cristianismo, y 'OpenGL ...' como gráficos de computadoras. Podemos probar con cosas más raras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soc.religion.christian', 'comp.graphics']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_new = ['God is a computer', 'God is computer graphics']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "[twenty_train.target_names[p] for p in predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que 'god' favorece mucho más a la clase 'christian' que 'computer' a la clase 'comp.graphics', pero al agregar 'graphics' termina siendo elegida 'comp.graphics'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Multinomial Naive-Bayes por Dentro\n",
    "\n",
    "Los parámetros de un modelo MNB son los siguientes:\n",
    "\n",
    "1. Probabilidad a priori de cada clase (prior): p(c).\n",
    "2. Probabilidad de un feature dada una clase: p(f|c).\n",
    "\n",
    "A continuación vemos cada una de las dos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad de clase\n",
    "\n",
    "En scikit-learn se guardan las log-probabilidades en el atributo `class_log_prior_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alt.atheism', 0.21267168808152423),\n",
       " ('comp.graphics', 0.25875055383252116),\n",
       " ('sci.med', 0.26318121400088634),\n",
       " ('soc.religion.christian', 0.26539654408506874)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import exp\n",
    "list(zip(twenty_train.target_names, exp(clf.class_log_prior_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá podemos ver que a priori la clase más probable es 'christian'. Esto se debe a que la mayoría de los documentos que se usaron para entrenar pertenecen a esta clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad de feature\n",
    "\n",
    "En scikit-learn se guardan las log-probabilidades en el atributo `feature_log_prob_`, que es una matriz (m, n) a donde m es la cantidad de clases y n la cantidad de features.\n",
    "\n",
    "Por ejemplo, podemos preguntar la probabilidad de la palabra 'god' para cada una de las clases viendo en la columna correspondiente a ese feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alt.atheism', 0.00037269074626827755),\n",
       " ('comp.graphics', 3.2614957950227121e-05),\n",
       " ('sci.med', 2.6122286434412079e-05),\n",
       " ('soc.religion.christian', 0.0007471829003996937)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = features.index('god')\n",
    "list(zip(twenty_train.target_names, exp(clf.feature_log_prob_[:,i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá se puede ver claramente que 'god' es mucho más probable en 'christian' y 'atheism' que en 'graphics' y 'med'.\n",
    "\n",
    "Veamos también las probabilidades para 'computer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alt.atheism', 6.3638553439577644e-05),\n",
       " ('comp.graphics', 0.00018187889710043111),\n",
       " ('sci.med', 0.00016266121829935505),\n",
       " ('soc.religion.christian', 5.5180221237835211e-05)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = features.index('computer')\n",
    "list(zip(twenty_train.target_names, exp(clf.feature_log_prob_[:,i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá vemos cómo 'computer' favorece 'graphics' y 'med' sobre 'atheism' y 'christian', pero también vemos que las priobabilidades no son tan altas como las de 'god'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n",
    "1. Terminar el [tutorial original](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html).\n",
    "2. Probar el clasificador sin hacer TF-IDF y ver qué da.\n",
    "2. Leer y tratar de entender el código fuente de la clase [MultinomialNB](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/naive_bayes.py#L562).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
