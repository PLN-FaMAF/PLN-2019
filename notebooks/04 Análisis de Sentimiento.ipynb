{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Sentimiento\n",
    "\n",
    "## Corpus de Tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment.tass import InterTASSReader\n",
    "\n",
    "reader = InterTASSReader('TASS/InterTASS/tw_faces4tassTrain1000rc.xml')\n",
    "tweets = list(reader.tweets())  # iterador sobre los tweets\n",
    "X = list(reader.X())  # iterador sobre los contenidos de los tweets\n",
    "y = list(reader.y())  # iterador sobre las polaridades de los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'OnceBukowski', 'sentiment': 'NONE', 'tweetid': '768213876278165504', 'date': '2016-08-23 22:30:35', 'content': '-Me caes muy bien \\n-Tienes que jugar más partidas al lol con Russel y conmigo\\n-Por qué tan Otako, deja de ser otako\\n-Haber si me muero', 'lang': 'es'}\n"
     ]
    }
   ],
   "source": [
    "print(tweets[0])\n",
    "#print(X[0])\n",
    "#print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sentiment/scripts/train.py -m clf -c maxent -o clf_maxent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment P:\n",
      "  Precision: 52.89% (119/225)\n",
      "  Recall: 76.28% (119/156)\n",
      "  F1: 62.47%\n",
      "Sentiment N:\n",
      "  Precision: 60.65% (131/216)\n",
      "  Recall: 59.82% (131/219)\n",
      "  F1: 60.23%\n",
      "Sentiment NEU:\n",
      "  Precision: 15.79% (3/19)\n",
      "  Recall: 4.35% (3/69)\n",
      "  F1: 6.82%\n",
      "Sentiment NONE:\n",
      "  Precision: 28.26% (13/46)\n",
      "  Recall: 20.97% (13/62)\n",
      "  F1: 24.07%\n",
      "Accuracy: 52.57% (266/506)\n",
      "Macro-Precision: 39.40%\n",
      "Macro-Recall: 40.35%\n",
      "Macro-F1: 39.87%\n",
      "\tP\tN\tNEU\tNONE\n",
      "P\t119\t27\t5\t5\t\n",
      "N\t60\t131\t7\t21\t\n",
      "NEU\t30\t29\t3\t7\t\n",
      "NONE\t16\t29\t4\t13\t\n"
     ]
    }
   ],
   "source": [
    "%run sentiment/scripts/eval.py -i clf_maxent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jugando con el Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@noseashetero 1000/10 de verdad a ti que voy a decir petarda que te quiero más que a mí mismo  ✨\n",
      "['P']\n",
      "[[0.03945864 0.07788631 0.11067046 0.77198459]]\n",
      "['N' 'NEU' 'NONE' 'P']\n"
     ]
    }
   ],
   "source": [
    "pipeline = model._pipeline\n",
    "x = X[0]\n",
    "# x = '@noseashetero 1000/10 de verdad a ti que voy a decir petarda que te quiero más que a mí mismo  ✨'\n",
    "y = pipeline.predict([x])\n",
    "P = pipeline.predict_proba([x])\n",
    "print(x)\n",
    "print(y)\n",
    "print(P)\n",
    "# print(type(P))  P es un array de numpy (o sea, una matriz)\n",
    "print(pipeline.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del Modelo y Errores\n",
    "\n",
    "Para el clasificador maxent podemos consultar las características que más favorecen o desfavorecen cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:\n",
      "\tportada buena enhorabuena gracias besos ([-1.57715354 -1.43077936 -1.42759822 -1.41947779 -1.36450292])\n",
      "\todio déficit recortes muertos triste ([1.6724519  1.68052657 1.78226641 2.04207167 2.42096484])\n",
      "NEU:\n",
      "\tparados cree enhorabuena cuenta puedes ([-1.11954982 -0.99833537 -0.93920145 -0.90387799 -0.8670128 ])\n",
      "\tdecidirán broma palomacervilla expectación huelga ([1.26041253 1.26806314 1.30022578 1.32740269 1.34231887])\n",
      "NONE:\n",
      "\tfeliz gracias interesante gran enhorabuena ([-1.95280773 -1.93897273 -1.84154676 -1.79116806 -1.70262616])\n",
      "\tperiódico sesión jugar reunión portada ([1.21813152 1.30945322 1.38032478 1.45742904 2.20772094])\n",
      "P:\n",
      "\tportada triste culpa urdangarin griñan ([-1.66217174 -1.54530836 -1.42478139 -1.31705283 -1.27911123])\n",
      "\tgenial homenaje gracias felicidades enhorabuena ([1.85082741 2.00512272 2.14249476 2.27528371 2.44819998])\n"
     ]
    }
   ],
   "source": [
    "# el model ya quedó cargado al haber corrido eval.py\n",
    "pipeline = model._pipeline\n",
    "vect = pipeline.named_steps['vect']\n",
    "clf = pipeline.named_steps['clf']\n",
    "\n",
    "from sentiment.analysis import print_maxent_features\n",
    "print_maxent_features(vect, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script de evaluación también calcula una matriz de confusión detallada \"cm_items\" para ver en qué instancias falla. Veamos las instancias que son negativas y fueron marcadas como positivas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cm_items['N', 'P'])\n",
    "X2 = [X[i] for i in cm_items['N', 'P']]  # obtenemos los contenidos\n",
    "# print(X2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando predict_proba podemos calcular los \"peores\" errores, esto es, los que más favorecieron P por encima de N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@sport JA JA JA JA JA  Teneis el ojino como la bandera de Japón ,hijos de la gran puta ',\n",
       "  0.8688556947282048),\n",
       " ('@carlachan Ja ja, hay gente muy cansina, sobre todo a partir de cierta edad, paciencia... ',\n",
       "  0.8102357071340037),\n",
       " ('@LovNaty Tu vida ha parido a un grandisimo hijo de la gran p... , un maravilloso hombre!!. ',\n",
       "  0.7749119307900135)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = pipeline.predict_proba(X2)  # calculamos las probabilidades para todas las clases\n",
    "# print(P.shape)\n",
    "# print(P[0])\n",
    "# print(pipeline.classes_)\n",
    "delta = P[:,3] - P[:,0]  # diferencia entre prob de P y prob de N\n",
    "# print(delta[0])\n",
    "# print(delta.shape)\n",
    "sorted_X2 = sorted(zip(X2, delta), key=lambda x: x[1], reverse=True)   # ordenamos de mayor a menor\n",
    "sorted_X2[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00652915 0.06819939 0.02362334 0.90164813]]\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.predict_proba(['JA JA JA JA JA']))\n",
    "# print(pipeline.decision_function(['JA JA JA JA JA']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá parece que las repeticiones afectan mucho!\n",
    "\n",
    "También se puede ver para una instancia particular, qué features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandera [-0.21837896 -0.06875349 -0.18659394  0.40750473]\n",
      "como [ 0.28427726 -0.02419825 -0.30479818 -0.02135281]\n",
      "de [ 0.14313646 -0.05570942 -0.17630761 -0.05663444]\n",
      "el [ 0.12529257  0.14119337 -0.35910615 -0.01771959]\n",
      "gran [-0.77341637  0.16377957 -1.79116806  1.43934252]\n",
      "hijos [-0.24858589  0.46061136  0.04537216 -0.41909758]\n",
      "ja [-0.67403068  0.09710408 -0.70453954  0.80007021]\n",
      "japón [ 0.07483029 -0.04713823 -0.05095741  0.03802967]\n",
      "la [ 0.18916709  0.03099955 -0.39759961 -0.00821768]\n",
      "puta [ 1.14006978 -0.41941094 -0.58078613 -0.61462698]\n",
      "teneis [ 0.09455496  0.19996237  0.17334524 -0.23311611]\n"
     ]
    }
   ],
   "source": [
    "from sentiment.analysis import print_feature_weights_for_item\n",
    "x = sorted_X2[0][0]\n",
    "print_feature_weights_for_item(vect, clf, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización\n",
    "\n",
    "Veamos por ejemplo cómo eliminar URLs y menciones de usuarios usando expresiones regulares. Tomemos un tweet de ejemplo que tenga ambas cosas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ha ardido una caravana aparcada al lado de la playa  \\nFuego ya sofocado por los bomberos @… https://t.co/LgbW9ryGWy'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [x for x in X if 'http' in x and '@' in x][0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ha ardido una caravana aparcada al lado de la playa  \\nFuego ya sofocado por los bomberos @… '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions = r'(?:@[^\\s]+)'  # una arroba seguida de uno o más caracteres que no son de espaciado\n",
    "urls = r'(?:https?\\://t.co/[\\w]+)'  # una URL http o https. \\w acepta letras, números y '_'.\n",
    "\n",
    "import re\n",
    "# re.sub(mentions, '', x)\n",
    "re.sub(urls, '', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negaciones\n",
    "\n",
    "Veamos una forma simple de manejar las negaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [x for x in X if 'no' in x.split()][0]\n",
    "# x\n",
    "x = 'las tengo pero aún no las he leído . Caerán prontito'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'las tengo pero aún no NOT_las NOT_he NOT_leído . Caerán prontito'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = x.split()\n",
    "new_tokens = []\n",
    "negate = False\n",
    "for token in tokens:\n",
    "    if token in ['no', 'tampoco']:\n",
    "        negate = True\n",
    "    elif token == '.':\n",
    "        negate = False\n",
    "    elif negate:\n",
    "        token = 'NOT_' + token\n",
    "    new_tokens.append(token)\n",
    "\n",
    "' '.join(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis\n",
    "\n",
    "Los emojis no deben ser filtrados ya que expresan sentimiento. Veamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Sakura_Abril Ow \n",
      "Bueno, no pasa nada, cuando puedas confirmarlo, estoy aquí 😊\n",
      "Y si no pudieras de cosplay pero sí a la expo, +\n"
     ]
    }
   ],
   "source": [
    "# pip install emoji\n",
    "import emoji\n",
    "emojis = set(emoji.UNICODE_EMOJI)\n",
    "x = [x for x in X if emojis & set(x.split())][0]  # buscamos algún ejemplo con emojis\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sakura_Abril',\n",
       " 'Ow',\n",
       " 'Bueno',\n",
       " 'no',\n",
       " 'pasa',\n",
       " 'nada',\n",
       " 'cuando',\n",
       " 'puedas',\n",
       " 'confirmarlo',\n",
       " 'estoy',\n",
       " 'aquí',\n",
       " 'si',\n",
       " 'no',\n",
       " 'pudieras',\n",
       " 'de',\n",
       " 'cosplay',\n",
       " 'pero',\n",
       " 'sí',\n",
       " 'la',\n",
       " 'expo']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "token_pattern = r\"(?u)\\b\\w\\w+\\b\"  # este es el patrón de tokenización que usa el count vectorizer\n",
    "re.findall(token_pattern, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que este tokenizador elimina los emojis y la puntuación. Veamos el tokenizador de NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'Sakura_Abril',\n",
       " 'Ow',\n",
       " 'Bueno',\n",
       " ',',\n",
       " 'no',\n",
       " 'pasa',\n",
       " 'nada',\n",
       " ',',\n",
       " 'cuando',\n",
       " 'puedas',\n",
       " 'confirmarlo',\n",
       " ',',\n",
       " 'estoy',\n",
       " 'aquí',\n",
       " '😊',\n",
       " 'Y',\n",
       " 'si',\n",
       " 'no',\n",
       " 'pudieras',\n",
       " 'de',\n",
       " 'cosplay',\n",
       " 'pero',\n",
       " 'sí',\n",
       " 'a',\n",
       " 'la',\n",
       " 'expo',\n",
       " ',',\n",
       " '+']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "word_tokenize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Mejor!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
